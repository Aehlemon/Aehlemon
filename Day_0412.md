## 🛠 Autoencoder (오토인코더)

- 개념: feature extraction 방법 중 하나로 Encoder 신경망과 Decoder 신경망으로 구성된 아키텍처

  - **Encoder**: 샘플 x에 연관된 d차원의 입력 특성 벡터 z를 받아 p차원의 벡터로 인코딩
    - 특징을 추출하며, `z = f(x)`함수를 모델링하는 방법을 배우는 역할, 데이터 압축 기능
    - 인코딩된 벡터를 latent 벡터 또는 잠재 특성 표현이라고 함

  - **Decoder**: 저차원 잠재 벡터 z에서 x 추론값(^)을 압축 해제함
    - 새로 학습한 표현을 원본형식으로 재구성(feature reconstruction)
    - 주어진 latent 벡터를 압축해제하여 원본차원으로 변환
    - 디코더를 함수 `x 추론값(^) = g(z)`로 생각할 수 있음





- 특징
  - **입력 shape = 출력 shape**
  - 일반적으로 Latent Space (잠재 공간)의 노드 수가 입력 값보다 작다 (Denoising autoencoder는 반대)
    - Latent Space: 입력된 Data를 가장 잘 표현하는 핵심적인 값만 갖고 있는 차원 
  - 데이터를 압축함
  - 차원을 축소함(중요한 Feature를 요약)
  - 비고) 오토 인코더의 구조는 항상 대칭적이지 않아도 됨 (사용자가 만들어 사용하기 나름)





- 구현방법

1. feature를 압축하여 가능한 만큼 feature의 갯수를 줄인다. (적당히 핵심 feature가 남도록)
2. 입력 → encoding → 차원축소 (latent space) → decoding → 출력





- 종류

1. 과소완전 AE : 내부의 표현이 입력 데이터보다 저차원이기 때문에 사용
2. 적층 AE : 여러 은닉층을 가진 AE를 Stacked AE 또는 Deep이라고 한다.
3. Denoising AE : 잡음은 입력에 추가된 순수한 가우시안이거나 드롭아웃처럼 무작위로 입력을 꺼서 발생시킬수도 있다.



 