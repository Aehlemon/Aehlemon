## ğŸ‘€ ì„œí¬íŠ¸ ë²¡í„°ë¨¸ì‹  (Support Vector Machine)

- ê°œë…:

  ***ì„œë¡œ ë‹¤ë¥¸ ë¶„ë¥˜ì— ì†í•œ ë°ì´í„° ê°„ì— ê°„ê²©(ë§ˆì§„, Margin)ì´ ìµœëŒ€ê°€ ë˜ëŠ” ì„ (ë˜ëŠ” ì´ˆí‰ë©´, hyperplane)ì„***

  ***ì°¾ì•„ì„œ ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸***

  

  - Support vector (ì§€ì§€ ë²¡í„°):  ì´ˆí‰ë©´ì— ê°€ì¥ ê°€ê¹Œìš´ í›ˆë ¨ ìƒ˜í”Œ
  -  Margin: ì´ˆí‰ë©´ê³¼ ê°€ì¥ ê°€ê¹Œìš´ í›ˆë ¨ ìƒ˜í”Œ(ì„œí¬íŠ¸ ë²¡í„°) ì‚¬ì´ ê±°ë¦¬

  - ë‘ ë²”ì£¼ ë˜ëŠ” ì—¬ëŸ¬ class ê°„ì˜ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë° ì„±ëŠ¥ì´ ë›°ì–´ë‚¨

  - Machine Learningì˜ í•œ ì¢…ë¥˜ë¡œ ì§€ë„í•™ìŠµ ëª¨ë¸ì´ë©°, `í…ìŠ¤íŠ¸ ë¶„ë¥˜, íŒ¨í„´ì¸ì‹, ë¶„ë¥˜ ë° íšŒê·€`ì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ”ë° ë¶„ë¥˜ëŠ” ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ê¸°ë²• ì¤‘ í•˜ë‚˜ë¡œì„œ N ì°¨ì›ì˜ ê³µê°„ì„ N-1 ì°¨ì›ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆëŠ” ì´ˆí‰ë©´ì„ ì°¾ëŠ” ë¶„ë¥˜ ê¸°ë²•ì´ë‹¤.

  - **Kernel Trick**:  ì €ì°¨ì› ê³µê°„ì—ì„œ ì„ í˜• ë¶„ë¦¬ê°€ ë˜ì§€ ì•ŠëŠ” ë°ì´í„°ë“¤ì„ ê³ ì°¨ì› ê³µê°„ìƒì— ë§¤í•‘ ì‹œì¼œì„œ ì„ í˜• ë¶„ë¦¬ë˜ë„ë¡ í•˜ëŠ” ê¸°ë²• (ex. XOR ë¶„ë¥˜ë¬¸ì œ)

  - ì´ë•Œ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ê°€ **Kernel Function**ì´ë‹¤. ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ë¡œëŠ”

    (ê°€ìš°ì‹œì•ˆ) RBF (Radial Basis Function) ì»¤ë„, ë‹¤í•­ì‹ ì»¤ë„, tanh, sigmoid, ìœ ì‚¬ë„ íŠ¹ì„± ë“±ì´ ìˆë‹¤



- ì¥ì 

  1. Noise Data ì˜í–¥ì„ í¬ê²Œ ë°›ì§€ ì•Šìœ¼ë©°, ê³¼ì í•©í™” (ì˜¤ë²„í”¼íŒ…)ê°€ ì˜ ë˜ì§€ ì•ŠìŒ

  2. (ì‹ ê²½ë§ ê¸°ë²•ì— ë¹„í•´) ë¶„ë¥˜ ë¬¸ì œì— ëŒ€í•œ ì„±ëŠ¥ì´ ë†’ìŒ

  3. ë¶„ë¥˜ ê²½ê³„ê°€ ë³µì¡í•œ ë¹„ì„ í˜• ë¬¸ì œì˜ ê²½ìš°, íƒ€ ê¸°ë²• ëŒ€ë¹„ ì„±ëŠ¥ ìš°ìˆ˜

  4. ë¶„ë¥˜ë¬¸ì œ, ì˜ˆì¸¡ ë¬¸ì œì— ëª¨ë‘ ì‚¬ìš© ê°€ëŠ¥

     

- ë‹¨ì 
  1. ëª¨ë¸ êµ¬ì¶• ì‹œ ì»¤ë„ í•¨ìˆ˜ ë° ë§¤ê°œ ë³€ìˆ˜ ë“±ì— ëŒ€í•œ ë°˜ë³µì ì¸ ì¡°í•© í…ŒìŠ¤íŠ¸ í•„ìš” 
  2. ì…ë ¥ ë°ì´í„° ì–‘, ë³€ìˆ˜ê°€ ë§ìœ¼ë©´ ì˜¤ëœ ì‹œê°„ì˜ í›ˆë ¨ í•„ìš”
  3.  ë‹¤ë¥¸ ê¸°ë²•ê³¼ ë¹„êµí•˜ì—¬ ë‚œí•´í•œ ë°°ê²½ ì´ë¡  ë° ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
  4. ê²°ê³¼ì— ëŒ€í•œ í•´ì„ì´ë‚˜ ì´ìœ  ì„¤ëª… ë“±ì´ ì–´ë ¤ì›€





#### - ì½”ë”© ì‹¤ìŠµ -

- Data set: Iris ë¶“ê½ƒ ë°ì´í„°

```python
import pandas as pd
import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Data ë¶ˆëŸ¬ì™€ì„œ ê²°ì¸¡ì¹˜, ì¤‘ë³µì¹˜ ì „ì²˜ë¦¬
iris = datasets.load_iris()
iris.keys() #dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])
iris["feature_names"]
# ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']

df = pd.DataFrame(iris['data'], columns=iris['feature_names'])
df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']

# Target ì—´ ì¶”ê°€
df['Target'] = iris['target']
print('ë°ì´í„°ì…‹ì˜ í¬ê¸°: ', df.shape) # ë°ì´í„°ì…‹ì˜ í¬ê¸°:  (150, 5)

df.isnull().sum()
df.duplicated().sum() # ì¤‘ë³µ ë°ì´í„° í™•ì¸
df.loc[df.duplicated(), :] # ì¤‘ë³µ ë°ì´í„° ìˆìœ¼ë©´ ìŠ¬ë¼ì´ì‹±
df.loc[(df.sepal_length==5.8)&(df.petal_width==1.9), :] # ì¤‘ë³µ ë°ì´í„° ëª¨ë‘ ì¶œë ¥
df = df.drop_duplicates() # ì¤‘ë³µ ë°ì´í„° ì œê±°: ìì£¼ ì‚¬ìš©
df.loc[(df.sepal_length==5.8)&(df.petal_width==1.9), :] # ì œê±° ë˜ì—ˆëŠ”ì§€ í™•ì¸

# Data Set ë¶„í• 
x_data = df.loc[:, "sepal_length":"petal_width"]
y_data = df.loc[:, "Target"]
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)

#ì„œí¬íŠ¸ë²¡í„°ë¨¸ì‹  ê°ì²´ ë§Œë“¤ê³ , fit, predict
svc = SVC()
svc.fit(x_train, y_train)
y_predict = svc.predict(x_train)
y_test_preict = svc.predict(x_test)
accuracy_score(y_train, y_predict) # 0.9747899159663865
accuracy_score(y_test, y_test_predict) # 0.9666666666666667



# GridSearchCV í™œìš©í•˜ì—¬ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° êµ¬í•˜ê¸°
# C: SVM ëª¨ë¸ì´ ë¶„ë¥˜í•  ë•Œ ì–´ëŠì •ë„ ì˜¤ì°¨ë¥¼ í—ˆìš©í•  ê±´ì§€ íŒë‹¨=> ì ë‹¹í•œ ê°’ì„ ì°¾ëŠ”ê²Œ ë² ìŠ¤íŠ¸!
# ë§ˆì§„ ë‚´ë¶€ì— ì˜¤ë¥˜ë¥¼ ì–¼ë§ˆ ë§Œí¼ í—ˆìš©í•  ê²ƒì¸ê°€?
# í•˜ë“œ ë§ˆì§„: c ì»¤ì§ˆ ìˆ˜ë¡ ì˜¤ë¥˜ë¥¼ í—ˆìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ (ì„±ëŠ¥ ì—°ê´€)
# ì†Œí”„íŠ¸ ë§ˆì§„: c ì‘ì•„ì§ˆ ìˆ˜ë¡ ì˜¤ë¥˜ë¥¼ ë§ì´ í—ˆìš© (ì¼ë°˜í™”ì— ì¢‹ìŒ)
# uniform: ê° ì´ì›ƒì´ ë™ì¼í•œ ê°€ì¤‘ì¹˜, distance: ê°€ê¹Œìš´ ì´ì›ƒì´ ë©€ë¦¬ ìˆëŠ” ì´ì›ƒë³´ë‹¤ í° ê°€ì¤‘ì¹˜
# degree: ë‹¤í•­ì‹ì˜ ì°¨ìˆ˜

from sklearn.model_selection import GridSearchCV

param_grid = {'C':[0.01,0.1,1, 10], 
               'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 
               'degree': [1,2,3,]}

gs = GridSearchCV(
    estimator = SVC(),
    param_grid = param_grid,
    n_jobs=2,
    verbose = True 
)

gs.fit(x_data, y_data)
# Fitting 5 folds for each of 48 candidates, totalling 240 fits
# GridSearchCV(estimator=SVC(), n_jobs=2,
#             param_grid={'C': [0.01, 0.1, 1, 10], 'degree': [1, 2, 3],
#                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},
#             verbose=True)

gs.best_params_ # {'C': 1, 'degree': 2, 'kernel': 'poly'}
gs.best_score_ # 0.9866666666666667
```





### SVM íšŒê·€

- SVMì€ ì„ í˜•, ë¹„ì„ í˜• ë¶„ë¥˜ ë¿ë§Œ ì•„ë‹ˆë¼ ì„ í˜•, ë¹„ì„ í˜• íšŒê·€ì—ë„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
- ë§ˆì§„ì„ ê²°ì •í•˜ê³  ìµœëŒ€í•œ Datasetì´ ë§ì´ ë“¤ì–´ê°€ê²Œ ë§Œë“¤ì–´ ì¤€ë‹¤.
- ì œí•œëœ ë§ˆì§„ ì˜¤ë¥˜ ì•ˆì—ì„œ ë„ë¡œ ì•ˆì— ê°€ëŠ¥í•œ í•œ ë§ì€ ìƒ˜í”Œì´ ë“¤ì–´ê°€ë„ë¡ í•™ìŠµí•œë‹¤.