## 👀 RNN (Recurrent Neural Network)

- 개념: 입력과 출력을 `시퀀스 단위`로 처리하는 시퀀스(Sequence) 모델
 - 활용: 언어 번역, 이미지 캡셔닝, 텍스트 생성 뿐만 아니라 리뷰 분석 등 다양한 분야에 활용된다. (꼭 언어적인 처리에만 국한된 것은 아님)
 - 예시) Input: 번역하고자 하는 단어의 시퀀스 문장, 시계열 데이터 등
         Output: 번역된 문장 또한 단어의 시퀀스, 미래 주가, 판매 추정량 등

**기본 원리** 
- 은닉층의 노드에서 활성화 함수를 통해 나온 결과 값을 출력층 방향으로도 보내면서, 
  다시 은닉층 노드의 다음 계산의 입력을 보낸다.
- 시퀀스 모델링을 위해 고안되어 모델 구동 시 입력 데이터 정보를 기억하고, 미래 얻게 될 값을 추정, 예측 가능

**관련 주요 용어**
- Keras layers로 모델명을 import하여 사용
  - `TimeSeriesGenerator`:
   - `length`:
   - `batch_size`:

  - RNN 셀 (메모리 셀): 은닉층에서 활성화 함수를 통해 결과를 내보내는 역할을 하는 노드
  - 은닉 상태 (hidden state): 메모리 셀이 출력층 방향 또는 다음 시점인 t+1의 자신에게 보내는 값

  - `hidden_units`: 은닉상태의 크기이자 메모리 셀의 용량
  - `timesteps`: 시점의 수 (자연어 처리에서는 보통 "문장의 길이")
  - `input_dim`: 입력값의 차원 (자연어 처리에서는 "입력 단어 벡터의 차원")
  - `return_sequences`: Defalut=False인데 순환층에서 시퀀스를 출력할지 마지막 출력만 반환할지 결정







